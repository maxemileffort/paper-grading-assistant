{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Grading Assistant\n",
    "\n",
    "## Modeling\n",
    "\n",
    "Data comes from this link:\n",
    "- https://www.kaggle.com/c/asap-aes/data\n",
    "\n",
    "Heavy inspiration drawn from:\n",
    "- https://towardsdatascience.com/topic-modeling-articles-with-nmf-8c6b2a227a45\n",
    "\n",
    "(Use incognito window when opening that link)\n",
    "\n",
    "## About this notebook\n",
    "\n",
    "This notebook is the part of the grading process where a teacher might categorize his or her students' papers by letter grade.\n",
    "\n",
    "The idea here is that the teacher will only need to adjust a few grades instead of having to grade an entire stack of papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim\n",
    "import os, sys\n",
    "from gensim import corpora, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\maxw2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\maxw2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Run the utilty functions from a seperate notebook\n",
    "%run topic_model_utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"D:\\\\Kaggle\\\\asap-aes\\\\training_set_rel3.tsv\", sep='\\t')\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokenized_essay'] = data.essay.apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN w/ 0\n",
    "data = data.fillna(0)\n",
    "\n",
    "# add a max_score column to use later \n",
    "# for standardizing scores, as all the \n",
    "# different essays sets have different \n",
    "# scales on which they were scored\n",
    "data['max_score'] = 0\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change max score col based on essay set\n",
    "# max vals:\n",
    "# set 1: 12\n",
    "# set 2: 10 or 24, needs some experimenting\n",
    "# set 3: 3\n",
    "# set 4: 3\n",
    "# set 5: 4\n",
    "# set 6: 4\n",
    "# set 7: 30\n",
    "# set 8: 60\n",
    "\n",
    "essay_sets = data.essay_set.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_ in essay_sets:\n",
    "    if set_ == 1:\n",
    "        data.loc[data.essay_set == set_, 'max_score'] = 12\n",
    "    if set_ == 2:\n",
    "        data.loc[data.essay_set == set_, 'max_score'] = 10\n",
    "    if set_ == 3 or set_ == 4:\n",
    "        data.loc[data.essay_set == set_, 'max_score'] = 3\n",
    "    if set_ == 5 or set_ == 6:\n",
    "        data.loc[data.essay_set == set_, 'max_score'] = 4\n",
    "    if set_ == 7:\n",
    "        data.loc[data.essay_set == set_, 'max_score'] = 30\n",
    "    if set_ == 8:\n",
    "        data.loc[data.essay_set == set_, 'max_score'] = 60\n",
    "# spot checking some of the data\n",
    "print(data.loc[data.essay_set == 1, 'max_score'])\n",
    "print(data.loc[data.essay_set == 4, 'max_score'])\n",
    "print(data.loc[data.essay_set == 7, 'max_score'])\n",
    "print(data.loc[data.essay_set == 8, 'max_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temp column for \n",
    "# model's later internal classes\n",
    "data['temp'] = 0\n",
    "for set_ in essay_sets:\n",
    "    if set_ == 2:\n",
    "        data.loc[data.essay_set == set_, 'temp'] = (data.loc[data.essay_set==set_,'domain1_score'] \\\n",
    "                                                   + data.loc[data.essay_set==set_,'domain2_score']) \\\n",
    "                                                   / data.loc[data.essay_set==set_,'max_score']\n",
    "        continue\n",
    "    else:\n",
    "        data.loc[data.essay_set == set_, 'temp'] = data.loc[data.essay_set==set_,'domain1_score'] \\\n",
    "                                                   / data.loc[data.essay_set==set_,'max_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-classify each paper on a scale of 1-5,\n",
    "# with 5 being a high score (like an A on an \n",
    "# ABCDF scale)\n",
    "data['class'] = 1\n",
    "for x in range(len(data)):\n",
    "    if (data.temp[x]) >= .9:\n",
    "        data['class'][x] = 5\n",
    "        continue\n",
    "    elif data.temp[x] >= .8 and data.temp[x] < .9:\n",
    "        data['class'][x] = 4\n",
    "        continue\n",
    "    elif data.temp[x] >= .7 and data.temp[x] < .8:\n",
    "        data['class'][x] = 3\n",
    "        continue\n",
    "    elif data.temp[x] >= .6 and data.temp[x] < .7:\n",
    "        data['class'][x] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "no_features = 1000\n",
    "\n",
    "# Initialize tf-idf\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.85, \n",
    "                                   min_df=3, \n",
    "                                   max_features=no_features, \n",
    "                                   stop_words='english', \n",
    "                                   preprocessor=' '.join)\n",
    "tfidf = tfidf_vectorizer.fit_transform(data['tokenized_essay'])\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# Bag of words\n",
    "tf_vectorizer = CountVectorizer(max_df=0.85, \n",
    "                                min_df=3, \n",
    "                                max_features=no_features, \n",
    "                                stop_words='english', \n",
    "                                preprocessor=' '.join)\n",
    "tf = tf_vectorizer.fit_transform(data['tokenized_essay'])\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "# Word2Vec\n",
    "word2vec = WordEmbeddingsService()\n",
    "word2vec_model = word2vec.train_w2v_model(tokenized_text=data['tokenized_essay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a few different vecotrizations of the data\n",
    "# to see which version does the best\n",
    "\n",
    "X_tfidf = tfidf\n",
    "X_tf = tf\n",
    "X_w2v = word2vec.create_word_embeddings(data['tokenized_essay'], word2vec_model)\n",
    "y = data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the different classifiers \n",
    "# to test with the paper scores\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"scipy\", message=\"^internal gelsd\")\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_classification(classifier, X, y, rs=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = rs)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    cm, acc_score, prec_score, rec_score = make_confusion_matrix(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return cm, acc_score, f1, prec_score, rec_score\n",
    "\n",
    "def make_confusion_matrix(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    acc_score = accuracy_score(y_test, y_pred)\n",
    "    prec_score = precision_score(y_test, y_pred, average='weighted')\n",
    "    rec_score = recall_score(y_test, y_pred, average='weighted')\n",
    "    return cm, acc_score, prec_score, rec_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of all the different classifiers\n",
    "# to loop through.\n",
    "# There are some unsupervised models just for comparison.\n",
    "classifiers = {\n",
    "    \"knn\": KNeighborsClassifier(n_neighbors = 3, metric = 'minkowski', p = 2),\n",
    "    \"nb\" : MultinomialNB(), \n",
    "    \"log_reg\": LogisticRegression(random_state=0),\n",
    "    \"lin_svm\" : SVC(kernel = 'linear', random_state = 0), # took too long with word2vec (more than 5000 secs)\n",
    "    \"rbf_svm\" : SVC(kernel = 'rbf', random_state = 0),\n",
    "    \"tree\" : DecisionTreeClassifier(criterion = 'entropy', random_state = 0),\n",
    "    \"rf\" : RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0),\n",
    "    \"ada\" : AdaBoostClassifier(random_state = 0),\n",
    "    \"gb\" : GradientBoostingClassifier(random_state = 0),\n",
    "    \"xgb\" : XGBClassifier(random_state = 0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf vectors first, 3 min\n",
    "tfidf_res = {}\n",
    "for key in classifiers.keys():\n",
    "    print(key)\n",
    "    cm, acc, f1, prec, rec = make_classification(classifiers[key], X_tfidf, y)\n",
    "    tfidf_res[key] = {\n",
    "        'cm' : cm,\n",
    "        'acc' : acc,\n",
    "        'f1' : f1,\n",
    "        'prec' : prec,\n",
    "        'rec' : rec\n",
    "    }\n",
    "    print(\"==============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat classification with bag of words models, 2.5 min\n",
    "tf_res = {}\n",
    "for key in classifiers.keys():\n",
    "    print(key)\n",
    "    cm, acc, f1, prec, rec = make_classification(classifiers[key], X_tf, y)\n",
    "    print(\"==============\")\n",
    "    tf_res[key] = {\n",
    "        'cm' : cm,\n",
    "        'acc' : acc,\n",
    "        'f1' : f1,\n",
    "        'prec' : prec,\n",
    "        'rec' : rec\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat classification with word2vec models, 5 min\n",
    "w2v_res = {}\n",
    "for key in classifiers.keys():\n",
    "    # lin_svm takes more than 1 hour on its own.\n",
    "    # nb doesn't accept negative numbers from the vectors.\n",
    "    if key == 'lin_svm' or key == 'nb': \n",
    "        continue\n",
    "    print(key)\n",
    "    try:\n",
    "        cm, acc, f1, prec, rec = make_classification(classifiers[key], X_w2v, y)\n",
    "    except:\n",
    "        cm, acc, f1, prec, rec = 0,0,0,0,0\n",
    "    print(\"==============\")\n",
    "    w2v_res[key] = {\n",
    "        'cm' : cm,\n",
    "        'acc' : acc,\n",
    "        'f1' : f1,\n",
    "        'prec' : prec,\n",
    "        'rec' : rec\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# everything else being equal,\n",
    "# we want the one with highest precisions \n",
    "# (precision is affected by FP, which would be \n",
    "# overestimation of the grade of the paper)\n",
    "\n",
    "for key in classifiers.keys():\n",
    "    try:\n",
    "        print(key)\n",
    "        print(\"==================\")\n",
    "        print(\"tfidf acc: \", tfidf_res[key]['acc'])\n",
    "        print(\"tfidf f1: \", tfidf_res[key]['f1'])\n",
    "        print(\"tfidf precision: \", tfidf_res[key]['prec'])\n",
    "        print(\"tfidf recall: \", tfidf_res[key]['rec'])\n",
    "        print(\"==================\")\n",
    "        print(\"tf acc: \", tf_res[key]['acc'])\n",
    "        print(\"tf f1: \", tf_res[key]['f1'])\n",
    "        print(\"tf precision: \", tf_res[key]['prec'])\n",
    "        print(\"tf recall: \", tf_res[key]['rec'])\n",
    "        print(\"==================\")\n",
    "        print(\"w2v acc: \", w2v_res[key]['acc'])\n",
    "        print(\"w2v f1: \", w2v_res[key]['f1'])\n",
    "        print(\"w2v precision: \", w2v_res[key]['prec'])\n",
    "        print(\"w2v recall: \", w2v_res[key]['rec'])\n",
    "        print(\"==================\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the best results from the training above. \n",
    "\n",
    "*Note:* I left out the unsupervised learning models because I generally just like to test them for a \"shot in the dark\" type of look at finding the optimal model. I attribute this to a short stent as a marketer where testing EVERYTHING was an important part of the puzzle.\n",
    "\n",
    "### log_reg\n",
    "- tfidf acc:  0.6879815100154083\n",
    "- tfidf f1:  0.6826731058258083\n",
    "- tfidf precision:  0.6840742515662983\n",
    "- tfidf recall:  0.6879815100154083\n",
    "\n",
    "### lin_svm\n",
    "- tfidf acc:  0.6798921417565486\n",
    "- tfidf f1:  0.6796612464208107\n",
    "- tfidf precision:  0.6851511607249138\n",
    "- tfidf recall:  0.6798921417565486\n",
    "\n",
    "### rbf_svm\n",
    "- tf acc:  0.714175654853621\n",
    "- tf f1:  0.7137245090277426\n",
    "- tf precision:  0.7245950249260565\n",
    "- tf recall:  0.714175654853621\n",
    "\n",
    "### tree\n",
    "- tfidf acc:  0.6302003081664098\n",
    "- tfidf f1:  0.6289259312408813\n",
    "- tfidf precision:  0.6278195501435767\n",
    "- tfidf recall:  0.6302003081664098\n",
    "\n",
    "### rf\n",
    "- tfidf acc:  0.687211093990755\n",
    "- tfidf f1:  0.6795152273421196\n",
    "- tfidf precision:  0.6789466187123883\n",
    "- tfidf recall:  0.687211093990755\n",
    "\n",
    "### ada\n",
    "- tf acc:  0.5670261941448382\n",
    "- tf f1:  0.5388070054332165\n",
    "- tf precision:  0.5626726131804644\n",
    "- tf recall:  0.5670261941448382\n",
    "\n",
    "\n",
    "### gb\n",
    "- tfidf acc:  0.7126348228043143\n",
    "- tfidf f1:  0.7112178825280995\n",
    "- tfidf precision:  0.7124145728645078\n",
    "- tfidf recall:  0.7126348228043143\n",
    "\n",
    "### These were the best of the word2vec models (Gradient boosting)\n",
    "- w2v acc:  0.6771956856702619\n",
    "- w2v f1:  0.6786444062419466\n",
    "- w2v precision:  0.6813704223813889\n",
    "- w2v recall:  0.6771956856702619\n",
    "\n",
    "### xgb\n",
    "- tfidf acc:  0.7245762711864406\n",
    "- tfidf f1:  0.7223852160700287\n",
    "- tfidf precision:  0.7212926330136676\n",
    "- tfidf recall:  0.7245762711864406\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in classifiers.keys():\n",
    "    try:\n",
    "        print(key)\n",
    "        print(\"==================\")\n",
    "        print(\"tfidf cm: \\n\", tfidf_res[key]['cm'])\n",
    "        print(\"==================\")\n",
    "        print(\"tf cm: \\n\", tf_res[key]['cm'])\n",
    "        print(\"==================\")\n",
    "        print(\"w2v cm: \\n\", w2v_res[key]['cm'])\n",
    "    except:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e301189debc5177601bb5c59a11b2befed8768132b1b8ef50f2e30593072dd97"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
