{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Paper Grading Assistant\r\n",
    "\r\n",
    "## Modeling\r\n",
    "\r\n",
    "Data comes from this link:\r\n",
    "- https://www.kaggle.com/c/asap-aes/data\r\n",
    "\r\n",
    "Heavy inspiration drawn from:\r\n",
    "- https://towardsdatascience.com/topic-modeling-articles-with-nmf-8c6b2a227a45\r\n",
    "\r\n",
    "(Use incognito window when opening that link)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# !pip install gensim\r\n",
    "import os, sys\r\n",
    "from gensim import corpora, models\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import pandas as pd\r\n",
    "import re\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Helper Functions\r\n",
    "# Run the utilty functions from a seperate notebook\r\n",
    "%run topic_model_utils.ipynb\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# data = grab_text(\"D:\\\\Kaggle\\\\paul-graham-essays\\\\paul_graham_essay.txt\")\r\n",
    "data = pd.read_csv(\"D:\\\\Kaggle\\\\asap-aes\\\\training_set_rel3.tsv\", sep='\\t')\r\n",
    "# data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data['tokenized_essay'] = data.essay.apply(process_text)\r\n",
    "data['max_score'] = 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# replace NaN w/ 0\r\n",
    "data = data.fillna(0)\r\n",
    "# add a max_score column to use later \r\n",
    "# for standardizing scores\r\n",
    "data['max_score'] = 0\r\n",
    "data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# change max score col based on essay set\r\n",
    "# max vals:\r\n",
    "# set 1: 12\r\n",
    "# set 2: 10 or 24, needs some experimenting\r\n",
    "# set 3: 3\r\n",
    "# set 4: 3\r\n",
    "# set 5: 4\r\n",
    "# set 6: 4\r\n",
    "# set 7: 30\r\n",
    "# set 8: 60\r\n",
    "essay_sets = data.essay_set.unique()\r\n",
    "for set_ in essay_sets:\r\n",
    "    print(set_)\r\n",
    "    if set_ == 1:\r\n",
    "        data.loc[data.essay_set == set_, 'max_score'] = 12\r\n",
    "    if set_ == 2:\r\n",
    "        data.loc[data.essay_set == set_, 'max_score'] = 10\r\n",
    "    if set_ == 3 or set_ == 4:\r\n",
    "        data.loc[data.essay_set == set_, 'max_score'] = 3\r\n",
    "    if set_ == 5 or set_ == 6:\r\n",
    "        data.loc[data.essay_set == set_, 'max_score'] = 4\r\n",
    "    if set_ == 7:\r\n",
    "        data.loc[data.essay_set == set_, 'max_score'] = 30\r\n",
    "    if set_ == 8:\r\n",
    "        data.loc[data.essay_set == set_, 'max_score'] = 60\r\n",
    "print(data.loc[data.essay_set == 1, 'max_score'])\r\n",
    "print(data.loc[data.essay_set == 4, 'max_score'])\r\n",
    "print(data.loc[data.essay_set == 7, 'max_score'])\r\n",
    "print(data.loc[data.essay_set == 8, 'max_score'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create temp column for \r\n",
    "# models later internal classes\r\n",
    "data['temp'] = 0\r\n",
    "for set_ in essay_sets:\r\n",
    "    if set_ == 2:\r\n",
    "        data.loc[data.essay_set == set_, 'temp'] = data.loc[data.essay_set==set_,'domain1_score'] + data.loc[data.essay_set==set_,'domain2_score'] / data.loc[data.essay_set==set_,'max_score']\r\n",
    "        continue\r\n",
    "    else:\r\n",
    "        data.loc[data.essay_set == set_, 'temp'] = data.loc[data.essay_set==set_,'domain1_score'] / data.loc[data.essay_set==set_,'max_score']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data['class'] = 1\r\n",
    "for x in range(len(data)):\r\n",
    "    if (data.temp[x]) >= .9:\r\n",
    "        data['class'][x] = 5\r\n",
    "        continue\r\n",
    "    elif data.temp[x] >= .8 and data.temp[x] < .9:\r\n",
    "        data['class'][x] = 4\r\n",
    "        continue\r\n",
    "    elif data.temp[x] >= .7 and data.temp[x] < .8:\r\n",
    "        data['class'][x] = 3\r\n",
    "        continue\r\n",
    "    elif data.temp[x] >= .6 and data.temp[x] < .7:\r\n",
    "        data['class'][x] = 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\r\n",
    "%run topic_model_utils.ipynb # for debugging\r\n",
    "\r\n",
    "no_features = 1000\r\n",
    "\r\n",
    "# Initialize tf-idf\r\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.85, \r\n",
    "                                   min_df=3, \r\n",
    "                                   max_features=no_features, \r\n",
    "                                   stop_words='english', \r\n",
    "                                   preprocessor=' '.join)\r\n",
    "tfidf = tfidf_vectorizer.fit_transform(data['tokenized_essay'])\r\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\r\n",
    "\r\n",
    "# Bag of words\r\n",
    "tf_vectorizer = CountVectorizer(max_df=0.85, \r\n",
    "                                min_df=3, \r\n",
    "                                max_features=no_features, \r\n",
    "                                stop_words='english', \r\n",
    "                                preprocessor=' '.join)\r\n",
    "tf = tf_vectorizer.fit_transform(data['tokenized_essay'])\r\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\r\n",
    "\r\n",
    "# Word2Vec\r\n",
    "word2vec = WordEmbeddingsService()\r\n",
    "word2vec_model = word2vec.train_w2v_model(tokenized_text=data['tokenized_essay'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_tfidf = tfidf\r\n",
    "X_tf = tf\r\n",
    "X_w2v = word2vec.create_word_embeddings(data['tokenized_essay'], word2vec_model)\r\n",
    "y = data['class']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print((y.unique()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "import warnings\r\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\r\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"scipy\", message=\"^internal gelsd\")\r\n",
    "\r\n",
    "from xgboost import XGBClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def make_classification(classifier, X, y, rs=42):\r\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = rs)\r\n",
    "    try:\r\n",
    "        classifier.fit(X_train, y_train)\r\n",
    "    except:\r\n",
    "        X_train = np.array(X_train)\r\n",
    "        X_test = np.array(X_test)\r\n",
    "        y_train = np.array(y_train)\r\n",
    "        y_test = np.array(y_test)\r\n",
    "        classifier.fit(X_train, y_train)\r\n",
    "    y_pred = classifier.predict(X_test)\r\n",
    "    cm, acc_score, prec_score, rec_score = make_confusion_matrix(y_test, y_pred)\r\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\r\n",
    "    return cm, acc_score, f1, prec_score, rec_score\r\n",
    "\r\n",
    "def make_confusion_matrix(y_test, y_pred):\r\n",
    "    cm = confusion_matrix(y_test, y_pred)\r\n",
    "    acc_score = accuracy_score(y_test, y_pred)\r\n",
    "    prec_score = precision_score(y_test, y_pred, average='weighted')\r\n",
    "    rec_score = recall_score(y_test, y_pred, average='weighted')\r\n",
    "    return cm, acc_score, prec_score, rec_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "classifiers = {\r\n",
    "    \"log_reg\": LogisticRegression(random_state=0),\r\n",
    "    \"knn\": KNeighborsClassifier(n_neighbors = 3, metric = 'minkowski', p = 2),\r\n",
    "    \"lin_svm\" : SVC(kernel = 'linear', random_state = 0), # took too long with word2vec (more than 5000 secs)\r\n",
    "    \"rbf_svm\" : SVC(kernel = 'rbf', random_state = 0),\r\n",
    "    \"nb\" : MultinomialNB(), \r\n",
    "    \"tree\" : DecisionTreeClassifier(criterion = 'entropy', random_state = 0),\r\n",
    "    \"rf\" : RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0),\r\n",
    "    \"ada\" : AdaBoostClassifier(random_state = 0),\r\n",
    "    \"gb\" : GradientBoostingClassifier(random_state = 0),\r\n",
    "    \"xgb\" : XGBClassifier(random_state = 0),\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# tfidf vectors first, 15 min\r\n",
    "tfidf_res = {}\r\n",
    "for key in classifiers.keys():\r\n",
    "    print(key)\r\n",
    "    cm, acc, f1, prec, rec = make_classification(classifiers[key], X_tfidf, y)\r\n",
    "    tfidf_res[key] = {\r\n",
    "        'cm' : cm,\r\n",
    "        'acc' : acc,\r\n",
    "        'f1' : f1,\r\n",
    "        'prec' : prec,\r\n",
    "        'rec' : rec\r\n",
    "    }\r\n",
    "    print(\"==============\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# repeat classification with bag of words models, 6 min\r\n",
    "tf_res = {}\r\n",
    "for key in classifiers.keys():\r\n",
    "    print(key)\r\n",
    "    cm, acc, f1, prec, rec = make_classification(classifiers[key], X_tf, y)\r\n",
    "    print(\"==============\")\r\n",
    "    tf_res[key] = {\r\n",
    "        'cm' : cm,\r\n",
    "        'acc' : acc,\r\n",
    "        'f1' : f1,\r\n",
    "        'prec' : prec,\r\n",
    "        'rec' : rec\r\n",
    "    }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# repeat classification with word2vec models, 45 min\r\n",
    "w2v_res = {}\r\n",
    "for key in classifiers.keys():\r\n",
    "    # if key == 'lin_svm':\r\n",
    "    #     continue\r\n",
    "    print(key)\r\n",
    "    cm, acc, f1, prec, rec = make_classification(classifiers[key], X_w2v, y)\r\n",
    "    print(\"==============\")\r\n",
    "    w2v_res[key] = {\r\n",
    "        'cm' : cm,\r\n",
    "        'acc' : acc,\r\n",
    "        'f1' : f1,\r\n",
    "        'prec' : prec,\r\n",
    "        'rec' : rec\r\n",
    "    }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# everything else being equal,\r\n",
    "# we want the one with highest precisions \r\n",
    "# (precision is affected by FP, which would be \r\n",
    "# overestimation of the grade of the paper)\r\n",
    "\r\n",
    "for key in classifiers.keys():\r\n",
    "    try:\r\n",
    "        print(key)\r\n",
    "        print(\"==================\")\r\n",
    "        print(\"tfidf acc: \", tfidf_res[key]['acc'])\r\n",
    "        print(\"tfidf f1: \", tfidf_res[key]['f1'])\r\n",
    "        print(\"tfidf precision: \", tfidf_res[key]['prec'])\r\n",
    "        print(\"tfidf recall: \", tfidf_res[key]['rec'])\r\n",
    "        print(\"==================\")\r\n",
    "        print(\"tf acc: \", tf_res[key]['acc'])\r\n",
    "        print(\"tf f1: \", tf_res[key]['f1'])\r\n",
    "        print(\"tf precision: \", tf_res[key]['prec'])\r\n",
    "        print(\"tf recall: \", tf_res[key]['rec'])\r\n",
    "        print(\"==================\")\r\n",
    "        print(\"w2v acc: \", w2v_res[key]['acc'])\r\n",
    "        print(\"w2v f1: \", w2v_res[key]['f1'])\r\n",
    "        print(\"w2v precision: \", w2v_res[key]['prec'])\r\n",
    "        print(\"w2v recall: \", w2v_res[key]['rec'])\r\n",
    "        print(\"==================\")\r\n",
    "    except:\r\n",
    "        pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here are the best results from the training above.\r\n",
    "\r\n",
    "### log_reg\r\n",
    "- tfidf acc:  0.6879815100154083\r\n",
    "- tfidf f1:  0.6826731058258083\r\n",
    "- tfidf precision:  0.6840742515662983\r\n",
    "- tfidf recall:  0.6879815100154083\r\n",
    "### lin_svm\r\n",
    "- tfidf acc:  0.6798921417565486\r\n",
    "- tfidf f1:  0.6796612464208107\r\n",
    "- tfidf precision:  0.6851511607249138\r\n",
    "- tfidf recall:  0.6798921417565486\r\n",
    "### rbf_svm\r\n",
    "- tf acc:  0.714175654853621\r\n",
    "- tf f1:  0.7137245090277426\r\n",
    "- tf precision:  0.7245950249260565\r\n",
    "- tf recall:  0.714175654853621\r\n",
    "\r\n",
    "### tree\r\n",
    "- tfidf acc:  0.6302003081664098\r\n",
    "- tfidf f1:  0.6289259312408813\r\n",
    "- tfidf precision:  0.6278195501435767\r\n",
    "- tfidf recall:  0.6302003081664098\r\n",
    "### rf\r\n",
    "- tfidf acc:  0.687211093990755\r\n",
    "- tfidf f1:  0.6795152273421196\r\n",
    "- tfidf precision:  0.6789466187123883\r\n",
    "- tfidf recall:  0.687211093990755\r\n",
    "### ada\r\n",
    "- tf acc:  0.5670261941448382\r\n",
    "- tf f1:  0.5388070054332165\r\n",
    "- tf precision:  0.5626726131804644\r\n",
    "- tf recall:  0.5670261941448382\r\n",
    "\r\n",
    "\r\n",
    "### gb\r\n",
    "- tfidf acc:  0.7126348228043143\r\n",
    "- tfidf f1:  0.7112178825280995\r\n",
    "- tfidf precision:  0.7124145728645078\r\n",
    "- tfidf recall:  0.7126348228043143\r\n",
    "\r\n",
    "- w2v acc:  0.6771956856702619\r\n",
    "- w2v f1:  0.6786444062419466\r\n",
    "- w2v precision:  0.6813704223813889\r\n",
    "- w2v recall:  0.6771956856702619\r\n",
    "\r\n",
    "### xgb\r\n",
    "- tfidf acc:  0.7245762711864406\r\n",
    "- tfidf f1:  0.7223852160700287\r\n",
    "- tfidf precision:  0.7212926330136676\r\n",
    "- tfidf recall:  0.7245762711864406\r\n",
    "\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "interpreter": {
   "hash": "e301189debc5177601bb5c59a11b2befed8768132b1b8ef50f2e30593072dd97"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}